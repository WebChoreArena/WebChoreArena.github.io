<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="WebChoreArena is a platform for evaluating web browsing agents on realistic tedious web tasks.">
  <meta name="keywords" content="Web Browsing Agent, Benchmark">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>
    WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web Tasks</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/WebChoreArena-kun.jpg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web Tasks</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://atsumiyai.github.io/">Atsuyuki Miyai</a>,</span>
            <span class="author-block">
              Zaiying Zhao,
            </span>
            <span class="author-block">
              <a href="https://www.sri.inf.ethz.ch/people/kazuki">Kazuki Egashira</a>,
            </span>
            <span class="author-block">
              <a href="https://atsukisato.github.io/">Atsuki Sato</a>,
            </span>
            <span class="author-block">
              Tatsumi Sunada,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/shota-onohara/"> Shota Onohara</a>,
            </span>
            <span class="author-block">
              Hiromasa Yamanishi,
            </span>
            <span class="author-block">
              Mashiro Toyooka,
            </span>
            <span class="author-block">
              Kunato Nishina,
            </span>
            <span class="author-block">
              Ryoma Maeda,
            </span>
            <br>
            <span class="author-block">
              <a href="https://scholar.google.co.jp/citations?user=CJRhhi0AAAAJ&hl=en">Kiyoharu Aizawa</a>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.co.jp/citations?hl=ja&user=rE9iY5MAAAAJ&view_op=list_works">
                Toshihiko Yamasaki</a>
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">The University of Tokyo</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2506.01952"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2506.01952"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/WebChoreArena/WebChoreArena"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser.png" alt="teaser" style="max-width: 100%; height: auto;">
      <h2 class="subtitle has-text-centered">
        The WebChoreArena challenge. WebChoreArena extends WebArena by introducing
more complex and labor-intensive tasks, pushing the boundaries of agent capabilities. 
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Powered by a large language model (LLM), a web browsing agent operates web browsers in a human-like manner 
            and offers a highly transparent path toward automating a wide range of everyday tasks. 
            As web agents become increasingly capable and demonstrate proficiency in general browsing tasks, 
            a critical question emerges: Can they go beyond general browsing to robustly handle tasks 
            that are tedious and complex, or chores that humans often avoid doing themselves?
          </p>
          <p>
            In this paper, we introduce WebChoreArena, a new fully reproducible benchmark comprising 532 
            carefully curated tasks designed to extend the scope of WebArena beyond general browsing to 
            more labor-intensive and tedious tasks. WebChoreArena systematically integrates three key challenges:
            (i) Massive Memory tasks requiring accurate retrieval of large amounts of information in the observations, 
            (ii) Calculation tasks demanding precise mathematical reasoning, and (iii) Long-Term Memory tasks 
            necessitating long-term memory across multiple webpages. 
          </p>
          <p>
            Built on top of the fully reproducible and widely adopted four WebArena simulation environments, 
            WebChoreArena ensures strict reproducibility and enables fair, direct comparisons with the established WebArena benchmark, 
            offering key insights into agent progress. 
          </p> 
          <p>
            Our experimental results demonstrate that as LLMs evolve, represented 
            by GPT-4o, Claude 3.7 Sonnet, and Gemini 2.5 Pro, significant improvements in performance are observed on WebChoreArena. 
            These findings suggest that WebChoreArena is well-suited to measure the advancement of state-of-the-art LLMs with greater clarity. 
            Nevertheless, the results also indicate that even with Gemini 2.5 Pro, there remains substantial room for improvement compared 
            to WebArena, highlighting the increased challenges posed by WebChoreArena.
          </p>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <!-- Dataset Statistics. -->
      <div class="column">
        <div class="content has-text-left">
          <h2 class="title is-3 has-text-centered">Dataset Statistics</h2>

          <!-- First image and caption -->
          <h3 class="title is-4 has-text-centered" style="margin-top: 0.5rem; margin-bottom: 2.0rem;">
            Distribution of websites and task types
          </h3>
          <p>
            WebChoreArena includes a total of 532 human-curated tasks. These consist of 117 tasks for Shopping, 132 for Shopping Admin, 91 for Reddit, 127 for GitLab, and 65 Cross-site tasks that span multiple platforms.
          </p>
          <p>
            All tasks can be categorized into four types based on their reasoning requirements: Massive Memory tasks, Calculation tasks, Long-Term Memory tasks, and Others.
          </p>
          
          <img src="./static/images/task_distribution.png" alt="Task Distribution" style="max-width: 100%; height: auto; margin-bottom: 2rem;">

          <!-- Second image and caption -->
          <h3 class="title is-4 has-text-centered" style="margin-top: 0.5rem; margin-bottom: 2.0rem;">
            Example of Each Task Type
          </h3>
          (i) Massive Memory tasks require accurately memorizing a large amount of information from the given page. (ii) Calculation tasks
          involve performing arithmetic operations. (iii) Long-Term Memory tasks require the agent to retain
          relevant information across many steps and interactions. (iv) Others involve tasks that require special
          or domain-specific operations.
          <img src="./static/images/task_type.png" alt="Task Type Breakdown" style="max-width: 100%; height: auto; margin-bottom: 1rem;">
        </div>
      </div>
    </div>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <!-- Benchmark Construction. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3 has-text-centered">Benchmark Construction</h2>
          <p>
          We assigned three annotators (selected from the authors) to each of the four simulated websites. To ensure consistency in task quality across different websites, one annotator was assigned to all four websites. 
          In total, ten annotators were involved in the task creation process. This annotation process was both meticulous and labor-intensive, totaling over 300 hours.
          </p>
          <p><strong>1. Emphasis on Memory-intensive Analytical Tasks.</strong></p>
          <p>
            We deliberately focused on collecting tasks that require memory—that is, tasks in which information from past observations is essential to reach the correct answer.
            Such tasks are common in real-world scenarios but remain largely underrepresented in existing benchmarks such as WebArena.
          </p>
          <p>
            To avoid overly simplistic tasks, we first prototyped early task ideas and evaluated them using a Claude-based agent to identify model limitations and refine the task designs.
            This process ensured that our final tasks were both meaningful and appropriately challenging.
          </p>

          <p><strong>2. Reducing Ambiguity in Task Specification and Evaluation.</strong></p>
          <p>
            We explicitly instructed annotators to eliminate ambiguity in both task descriptions and evaluation criteria.
            While handling ambiguous instructions is important for agents aiming to operate flexibly in real-world human interactions, we prioritized clear evaluability, since reliable evaluation is essential for measuring progress.
          </p>
          <p>
            In WebArena, vague instructions often lead to scenarios where agents produce reasonable answers that are incorrectly marked as failures.
            In addition, we observed that the evaluation protocol in WebArena can fail to reliably assess answers due to vague output format expectations.
            To mitigate ambiguity in answer evaluation, we standardized the required output formats, <em>e.g.,</em> <em>"Provide only the answer without any additional words."</em>, when aiming for exact matching with the ground truth.
          </p>

          <p><strong>3. Template-based Task Construction and Extension.</strong></p>
          <p>
            Following WebArena, we instructed annotators to create task templates and extend them to several task instances.
            The annotators were also responsible for developing several instantiations for each variable.
            This templated design enables a more robust and systematic evaluation of agent performance across tasks that share semantic similarity but exhibit diverse execution traces.
          </p>
          <p>
            We created a total of 117 task templates: 25 for Shopping, 29 for Shopping Admin, 20 for Reddit, 28 for GitLab, and 15 for Cross-site tasks. 
            On average, each template yielded approximately 4.5 task instances. Here, WebArena includes several tasks based on the map website (OpenStreetMap). 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <!-- Dataset Statistics. -->
      <div class="column">
        <div class="content has-text-centered">
          <h2 class="title is-3">Experimental Results</h2>
          <p>
            The following figures illustrate the overall and task type-wise results on WebChoreArena.
          </p>

          <!-- First image and caption -->
          <h3 class="title is-4" style="margin-top: 0.1rem; margin-bottom: 0.3rem;">Overall Results</h3>
          <img src="./static/images/main_results.png" alt="Overall Results" style="max-width: 100%; height: auto; margin-bottom: 0.3rem;">

          <!-- Second image and caption -->
          <h3 class="title is-4" style="margin-top: 0.1rem; margin-bottom: 0.1rem;">Results per Task Type</h3>
          <img src="./static/images/results_per_task.png" alt="Results per Task Type" style="max-width: 100%; height: auto; margin-bottom: 0.3rem;">

          <div class="content has-text-left">
            <h4 class="title is-5">F1: GPT-4o Struggles Significantly on WebChoreArena.</h4>
            <p>
            It is evident that <strong>GPT-4o struggles significantly on WebChoreArena</strong>. This indicates that WebChoreArena is <strong>significantly more challenging</strong> than WebArena, emphasizing the need for more advanced LLMs to tackle these tasks.</p>
            <h4 class="title is-5">F2: Latest LLMs Show Progress but Have Significant Room for Improvement.</h4>
            As LLMs have evolved with models such as <strong>Claude 3.7 Sonnet</strong> and <strong>Gemini 2.5 Pro</strong>, their performance in WebChoreArena demonstrates improvements, but <strong>there remains significant room for further advancement</strong>.</p>
            <h4 class="title is-5">F3: WebChoreArena Enables a Clearer and Deeper Measurement of the Performance Differences among the Models.</h4>
            <p>WebChoreArena serves as a <strong>more effective benchmark</strong> for distinguishing model performance. Unlike WebArena, which presents a <strong>narrower performance spectrum</strong>, WebChoreArena exposes a <strong>substantial performance divergence</strong>. Therefore, WebChoreArena provides model developers and evaluators with <strong>clear insights into the strengths and weaknesses</strong> of each model.</p>
            <h4 class="title is-5">F4: WebChoreArena Enables Fine-grained Analysis of Task-specific Performance.</h4>
            Fig. 4 presents a <strong>detailed analysis</strong> of each agent’s performance across diverse task typologies. The results underscore the <strong>significant influence of agent architecture</strong>, beyond the type of LLMs, on type-wise performance.</p>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{miyai2025webchorearena,
  author    = {Miyai, Atsuyuki and Zhao, Zaiying and Egashira, Kazuki and Sato, Atsuki and Sunada, Tatsumi and Onohara, Shota and Yamanishi, Hiromasa and Toyooka, Mashiro and Nishina, Kunato and Maeda, Ryoma and Aizawa, Kiyoharu and Yamasaki, Toshihiko},
  title     = {WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web Tasks},
  journal   = {arXiv preprint arXiv:2506.01952},
  year      = {2025},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
